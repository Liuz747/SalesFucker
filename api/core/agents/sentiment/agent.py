"""
Sentiment Analysis Agent - ç®€åŒ–åè°ƒç‰ˆ

ä¸“æ³¨äºåè°ƒå„ä¸ªä¸“ä¸šç»„ä»¶ï¼Œæä¾›æ¸…æ™°çš„æƒ…æ„Ÿåˆ†ææœåŠ¡ã€‚
Agent æœ¬èº«åªè´Ÿè´£æµç¨‹æ§åˆ¶å’ŒçŠ¶æ€ç®¡ç†ï¼Œå…·ä½“ä¸šåŠ¡é€»è¾‘å§”æ‰˜ç»™ä¸“é—¨ç»„ä»¶ã€‚

æ ¸å¿ƒèŒè´£:
- ç»„ä»¶åè°ƒå’Œæµç¨‹æ§åˆ¶
- çŠ¶æ€ç®¡ç†å’Œé”™è¯¯å¤„ç†
- ç»„ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†
- å¯¹å¤–æ¥å£ç»Ÿä¸€
"""

from typing import Dict, Any
from langfuse import observe

from ..base import BaseAgent
from .multimodal_input_processor import MultimodalInputProcessor
from .sentiment_analyzer import SentimentAnalyzer
from .sales_prompt_generator import SalesPromptGenerator
from .prompt_matcher import PromptMatcher
from utils import get_current_datetime
from config import mas_config


class SentimentAnalysisAgent(BaseAgent):
    """
    æƒ…æ„Ÿåˆ†ææ™ºèƒ½ä½“ - ç®€åŒ–åè°ƒç‰ˆ

    ä½œä¸ºå¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æçš„ä¸»å…¥å£ï¼Œåè°ƒï¼š
    - å¤šæ¨¡æ€è¾“å…¥å¤„ç†
    - æƒ…æ„Ÿåˆ†æ
    - é”€å”®æç¤ºè¯ç”Ÿæˆ

    è®¾è®¡åŸåˆ™ï¼š
    - å•ä¸€èŒè´£ï¼šåªè´Ÿè´£åè°ƒï¼Œä¸å¤„ç†å…·ä½“ä¸šåŠ¡é€»è¾‘
    - ä¾èµ–æ³¨å…¥ï¼šç»„ä»¶å¯æ›¿æ¢ï¼Œä¾¿äºæµ‹è¯•
    - é”™è¯¯éš”ç¦»ï¼šç»„ä»¶å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹
    - çŠ¶æ€æ¸…æ™°ï¼šæ˜ç¡®çš„çŠ¶æ€ç®¡ç†å’Œæ›´æ–°
    - è®°å¿†æœåŠ¡ï¼šä»å·¥ä½œæµæ³¨å…¥ï¼Œä¸å†ç‹¬ç«‹ç®¡ç†
    """

    def __init__(self):
        super().__init__()
        self.llm_provider = mas_config.DEFAULT_LLM_PROVIDER

        # ä½¿ç”¨OpenRouterä¸­å¯ç”¨çš„æ¨¡å‹
        self.llm_model = "openai/gpt-5-chat"

        # ç§»é™¤ç‹¬ç«‹çš„ StorageManagerï¼Œæ”¹ä¸ºä»å·¥ä½œæµè·å–
        self.prompt_matcher = PromptMatcher()

        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.input_processor = MultimodalInputProcessor(
            tenant_id=getattr(self, 'tenant_id', None),
            config={
                "openai_api_key": getattr(self, '_get_openai_api_key', lambda: None)()
            }
        )

        self.sentiment_analyzer = SentimentAnalyzer(
            llm_provider=self.llm_provider,
            llm_model=self.llm_model,
            invoke_llm_fn=self.invoke_llm
        )

        self.prompt_generator = SalesPromptGenerator()

    @observe(name="sentiment-analysis", as_type="generation")
    async def process_conversation(self, state: dict) -> dict:
        """
        å¤„ç†å¯¹è¯çŠ¶æ€ä¸­çš„æƒ…æ„Ÿåˆ†æï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆè®°å¿†å’Œæ™ºèƒ½æç¤ºè¯åŒ¹é…ï¼‰

        å·¥ä½œæµç¨‹ï¼š
        1. è·å–å·¥ä½œæµä¼ é€’çš„è®°å¿†ä¸Šä¸‹æ–‡
        2. å¤šæ¨¡æ€è¾“å…¥å¤„ç†
        3. æƒ…æ„Ÿåˆ†æ
        4. æ—…ç¨‹é˜¶æ®µåˆ¤æ–­ï¼ˆå†™æ­»è§„åˆ™ï¼‰
        5. æç¤ºè¯æ™ºèƒ½åŒ¹é…
        6. çŠ¶æ€æ›´æ–°

        å‚æ•°:
            state: å½“å‰å¯¹è¯çŠ¶æ€ï¼ŒåŒ…å« customer_input, tenant_id, thread_id, memory_context

        è¿”å›:
            dict: æ›´æ–°åçš„å¯¹è¯çŠ¶æ€ï¼ŒåŒ…å« matched_prompt å’Œ memory_context
        """
        start_time = get_current_datetime()

        try:
            self.logger.info("=== Sentiment Agent ===")

            customer_input = state.get("customer_input", "")
            tenant_id = state.get("tenant_id")
            thread_id = state.get("thread_id")

            self.logger.debug(f"customer_inputå†…å®¹: {customer_input[:100]}...")

            # æ­¥éª¤1: è·å–å·¥ä½œæµä¼ é€’çš„è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆè€Œéç‹¬ç«‹æ£€ç´¢ï¼‰
            memory_context = state.get("memory_context", {"short_term": [], "long_term": []})
            self.logger.info(f"è®°å¿†æ£€ç´¢å®Œæˆ - çŸ­æœŸæ¶ˆæ¯æ•°: {len(memory_context['short_term'])}, é•¿æœŸæ‘˜è¦æ•°: {len(memory_context['long_term'])}")

            # æ­¥éª¤2: å¤„ç†å¤šæ¨¡æ€è¾“å…¥
            processed_text, multimodal_context = await self._process_input(customer_input)
            self.logger.info(f"å¤šæ¨¡æ€è¾“å…¥å¤„ç†å®Œæˆ - processed_texté•¿åº¦: {len(processed_text)}, contextç±»å‹: {multimodal_context.get('type')}")

            # æ­¥éª¤3: æ‰§è¡Œæƒ…æ„Ÿåˆ†æï¼ˆä½¿ç”¨çŸ­æœŸæ¶ˆæ¯å†å²+å½“å‰è¾“å…¥ï¼‰
            sentiment_result = await self._analyze_sentiment_with_history(processed_text, multimodal_context, memory_context['short_term'])
            self.logger.info(f"æƒ…æ„Ÿåˆ†æç»“æœ - sentiment: {sentiment_result.get('sentiment')}, score: {sentiment_result.get('score')}, urgency: {sentiment_result.get('urgency')}")
            self.logger.info(f"æƒ…æ„Ÿåˆ†ætokenç»Ÿè®¡ - tokens_used: {sentiment_result.get('tokens_used', 0)}")
            self.logger.info(f"æƒ…æ„Ÿåˆ†æä¸Šä¸‹æ–‡ - ä½¿ç”¨å†å²æ¶ˆæ¯æ•°: {len(memory_context['short_term'])}")

            # æ­¥éª¤4: åˆ¤æ–­å®¢æˆ·æ—…ç¨‹é˜¶æ®µ æŒ‰è½®æ¬¡çš„è§„åˆ™-å¾…ä¿®æ”¹
            journey_stage = self._determine_journey_stage(memory_context['short_term'])
            self.logger.info(f"æ—…ç¨‹é˜¶æ®µåˆ¤æ–­: {journey_stage} (åŸºäºå¯¹è¯è½®æ¬¡: {len(memory_context['short_term'])})")

            # æ­¥éª¤5: æ™ºèƒ½åŒ¹é…æç¤ºè¯
            matched_prompt = self._match_prompt(sentiment_result.get('score', 0.5), journey_stage)
            self.logger.info(f"æç¤ºè¯åŒ¹é…å®Œæˆ - matched_key: {matched_prompt['matched_key']}, tone: {matched_prompt['tone']}")
            self.logger.debug(f"matched_promptå†…å®¹: {matched_prompt['system_prompt'][:150]}..." if len(matched_prompt['system_prompt']) > 150 else f"matched_promptå†…å®¹: {matched_prompt['system_prompt']}")

            # æ­¥éª¤6: æ›´æ–°å¯¹è¯çŠ¶æ€
            updated_state = self._update_state_enhanced(
                state, processed_text, sentiment_result, matched_prompt,
                multimodal_context, memory_context, journey_stage

            )

            processing_time = (get_current_datetime() - start_time).total_seconds()
            self.logger.info(f"æƒ…æ„Ÿåˆ†æå®Œæˆï¼ˆå¢å¼ºç‰ˆï¼‰: è€—æ—¶{processing_time:.2f}s, æƒ…æ„Ÿ={sentiment_result.get('sentiment')}, æ—…ç¨‹={journey_stage}")
            self.logger.info("=== Sentiment Agent å¤„ç†å®Œæˆï¼ˆå¢å¼ºç‰ˆï¼‰ ===")

            return updated_state

        except Exception as e:
            self.logger.error(f"æƒ…æ„Ÿåˆ†æå¤„ç†å¤±è´¥: {e}", exc_info=True)
            self.logger.error(f"å¤±è´¥æ—¶çš„è¾“å…¥: {state.get('customer_input', 'None')}")

    def _determine_journey_stage(self, short_term_messages: list) -> str:
        """
        æ–°å¢ï¼šåˆ¤æ–­å®¢æˆ·æ—…ç¨‹é˜¶æ®µï¼ˆå†™æ­»è§„åˆ™ï¼Œç®€å•å¯é ï¼‰

        Args:
            short_term_messages: çŸ­æœŸè®°å¿†æ¶ˆæ¯åˆ—è¡¨

        Returns:
            str: "awareness" | "consideration" | "decision"
        """
        try:
            # è®¡ç®—å¯¹è¯è½®æ¬¡ï¼ˆåªç®—ç”¨æˆ·æ¶ˆæ¯ï¼‰
            user_message_count = sum(
                1 for msg in short_term_messages
                if msg.get("role") == "user"
            )

            # å†™æ­»çš„ç®€å•è§„åˆ™
            if user_message_count <= 2:
                return "awareness"      # å‰1-2è½®ï¼šè®¤çŸ¥é˜¶æ®µ
            elif user_message_count <= 5:
                return "consideration"  # ç¬¬3-5è½®ï¼šè€ƒè™‘é˜¶æ®µ
            else:
                return "decision"       # ç¬¬6è½®+ï¼šå†³ç­–é˜¶æ®µ

        except Exception as e:
            self.logger.error(f"æ—…ç¨‹é˜¶æ®µåˆ¤æ–­å¤±è´¥: {e}")
            return "awareness"  # é»˜è®¤è¿”å›è®¤çŸ¥é˜¶æ®µ

    def _match_prompt(self, sentiment_score: float, journey_stage: str) -> dict:
        """
        æ–°å¢ï¼šæ™ºèƒ½åŒ¹é…æç¤ºè¯

        Args:
            sentiment_score: æƒ…æ„Ÿåˆ†æ•° 0.0-1.0
            journey_stage: æ—…ç¨‹é˜¶æ®µ

        Returns:
            dict: åŒ¹é…çš„æç¤ºè¯é…ç½®
        """
        try:
            # è°ƒç”¨ PromptMatcher æŸ¥è¡¨
            matched_prompt = self.prompt_matcher.get_prompt(
                sentiment_score=sentiment_score,
                journey_stage=journey_stage
            )

            self.logger.debug(f"æç¤ºè¯åŒ¹é…æˆåŠŸ - key: {matched_prompt.get('matched_key')}")
            return matched_prompt

        except Exception as e:
            self.logger.error(f"æç¤ºè¯åŒ¹é…å¤±è´¥: {e}")

    def _update_state_enhanced(
        self, state: dict, processed_text: str, sentiment_result: dict,
        matched_prompt: dict, multimodal_context: dict, memory_context: dict,
        journey_stage: str
    ) -> dict:
        """
        ğŸ”¥ æ–°å¢ï¼šå¢å¼ºç‰ˆçŠ¶æ€æ›´æ–°ï¼ˆæ·»åŠ  matched_prompt å’Œ memory_contextï¼‰

        Args:
            state: åŸå§‹çŠ¶æ€
            processed_text: å¤„ç†åçš„æ–‡æœ¬
            sentiment_result: æƒ…æ„Ÿåˆ†æç»“æœ
            matched_prompt: åŒ¹é…çš„æç¤ºè¯
            multimodal_context: å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
            memory_context: è®°å¿†ä¸Šä¸‹æ–‡
            journey_stage: æ—…ç¨‹é˜¶æ®µ

        Returns:
            dict: æ›´æ–°åçš„çŠ¶æ€
        """
        # æå–tokenä¿¡æ¯
        sentiment_tokens = {
            "tokens_used": sentiment_result.get("tokens_used", 0),
            "total_tokens": sentiment_result.get("total_tokens", 0)
        }

        # ğŸ”¥ å¢å¼ºç‰ˆï¼šæ ¹çº§åˆ«çŠ¶æ€ï¼ˆLangGraphèŠ‚ç‚¹é—´ä¼ é€’ï¼‰
        state["processed_text"] = processed_text
        state["matched_prompt"] = matched_prompt  # ğŸ†• SalesAgent å°†ä½¿ç”¨è¿™ä¸ª
        state["memory_context"] = memory_context  # ğŸ†• è®°å¿†ä¸Šä¸‹æ–‡
        state["journey_stage"] = journey_stage    # ğŸ†• æ—…ç¨‹é˜¶æ®µ

        # ä¿ç•™åŸæœ‰çš„ sentiment_analysis
        state["sentiment_analysis"] = {
            **sentiment_result,
            "journey_stage": journey_stage,        # ğŸ†• æ·»åŠ æ—…ç¨‹ä¿¡æ¯
            "processed_input": processed_text,
            "multimodal_context": multimodal_context,
            "agent_id": self.agent_id,
            **sentiment_tokens
        }

        # å¤‡ä»½å­˜å‚¨åœ¨ values ç»“æ„ä¸­ï¼ˆç”¨äºç»Ÿè®¡å’Œè°ƒè¯•ï¼‰
        if state.get("values") is None:
            state["values"] = {}
        if state["values"].get("agent_responses") is None:
            state["values"]["agent_responses"] = {}

        agent_data = {
            "sentiment_analysis": sentiment_result,
            "matched_prompt": matched_prompt,      # ğŸ†•
            "memory_context": memory_context,      # ğŸ†•
            "journey_stage": journey_stage,        # ğŸ†•
            "processed_input": processed_text,
            "timestamp": get_current_datetime(),
            **sentiment_tokens
        }

        state["values"]["agent_responses"][self.agent_id] = agent_data

        # æ›´æ–°æ´»è·ƒæ™ºèƒ½ä½“åˆ—è¡¨
        state.setdefault("active_agents", []).append(self.agent_id)

        self.logger.info(f"å¢å¼ºç‰ˆçŠ¶æ€ç®¡ç†å®Œæˆ - æ–°å¢å­—æ®µ: matched_prompt, memory_context, journey_stage")
        self.logger.info(f"çŠ¶æ€ä¼ é€’å®Œæˆ -> SalesAgent å¯è®¿é—®: state['matched_prompt'], state['memory_context']")

        return state

    async def _process_input(self, customer_input) -> tuple[str, dict]:
        """å¤„ç†å¤šæ¨¡æ€è¾“å…¥"""
        try:
            return await self.input_processor.process_input(customer_input)
        except Exception as e:
            self.logger.error(f"è¾“å…¥å¤„ç†å¤±è´¥: {e}")
            # é™çº§å¤„ç†ï¼šå°†è¾“å…¥è½¬ä¸ºå­—ç¬¦ä¸²
            return str(customer_input) if customer_input else "", {"type": "fallback", "error": str(e)}

    async def _analyze_sentiment(self, text: str, context: dict) -> dict:
        """åˆ†ææƒ…æ„Ÿ"""
        result = await self.sentiment_analyzer.analyze_sentiment(text, context)
        self.logger.info(f"æƒ…æ„Ÿåˆ†æå™¨è¿”å›ç»“æœ - sentiment: {result.get('sentiment')}, æƒ…æ„Ÿåˆ†ææ¶ˆè€—tokens: {result.get('total_tokens', 0)}")
        return result

    async def _analyze_sentiment_with_history(self, current_text: str, context: dict, short_term_msgs: list) -> dict:
        """
        ä½¿ç”¨å†å²æ¶ˆæ¯+å½“å‰è¾“å…¥è¿›è¡Œæƒ…æ„Ÿåˆ†æ

        Args:
            current_text: å½“å‰å¤„ç†çš„æ–‡æœ¬
            context: å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
            short_term_msgs: çŸ­æœŸå†å²æ¶ˆæ¯åˆ—è¡¨

        Returns:
            dict: æƒ…æ„Ÿåˆ†æç»“æœ
        """
        try:
            # è·å–æœ€è¿‘5æ¡ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            recent_user_messages = [
                msg.get("content", "") for msg in short_term_msgs[-5:]
                if msg.get("role") == "user" and msg.get("content", "").strip()
            ]

            # æ„å»ºåˆå¹¶çš„æ–‡æœ¬ç”¨äºåˆ†æ
            if recent_user_messages:
                # åˆ›å»ºå†å²å¯¹è¯ä¸Šä¸‹æ–‡
                history_context = "\n".join([f"ç”¨æˆ·æ¶ˆæ¯{i+1}: {msg}" for i, msg in enumerate(recent_user_messages)])
                combined_text = f"""æœ€è¿‘å¯¹è¯å†å²ï¼š
{history_context}

å½“å‰ç”¨æˆ·è¾“å…¥ï¼š
{current_text}"""

                self.logger.info(f"ä½¿ç”¨å†å²æ¶ˆæ¯è¿›è¡Œæƒ…æ„Ÿåˆ†æ - å†å²æ¶ˆæ¯æ•°: {len(recent_user_messages)}, åˆå¹¶åæ–‡æœ¬é•¿åº¦: {len(combined_text)}")

                # å¢å¼ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ ‡æ˜è¿™æ˜¯å†å²ä¸Šä¸‹æ–‡åˆ†æ
                enhanced_context = {
                    **context,
                    "analysis_type": "with_history",
                    "history_message_count": len(recent_user_messages),
                    "conversation_flow": "sequential"
                }

                # è°ƒç”¨åŸæœ‰çš„æƒ…æ„Ÿåˆ†ææ–¹æ³•
                result = await self.sentiment_analyzer.analyze_sentiment(combined_text, enhanced_context)

                # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯åˆ°ç»“æœä¸­
                result["analysis_context"] = {
                    "used_history": True,
                    "history_message_count": len(recent_user_messages),
                    "combined_text_length": len(combined_text),
                    "current_text_length": len(current_text)
                }

                self.logger.info(f"åŸºäºå†å²çš„æƒ…æ„Ÿåˆ†æå®Œæˆ - sentiment: {result.get('sentiment')}, ä½¿ç”¨å†å²æ¶ˆæ¯: {len(recent_user_messages)}æ¡")
                return result
            else:
                # æ²¡æœ‰å†å²æ¶ˆæ¯ï¼Œä½¿ç”¨å½“å‰æ–‡æœ¬åˆ†æ
                self.logger.info("æœªæ‰¾åˆ°å†å²ç”¨æˆ·æ¶ˆæ¯ï¼Œä½¿ç”¨å½“å‰æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†æ")
                result = await self.sentiment_analyzer.analyze_sentiment(current_text, context)

                result["analysis_context"] = {
                    "used_history": False,
                    "history_message_count": 0,
                    "combined_text_length": len(current_text),
                    "current_text_length": len(current_text)
                }

                return result

        except Exception as e:
            self.logger.error(f"åŸºäºå†å²çš„æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")

            return result

    async def _generate_prompt(self, sentiment_result: dict, context: dict) -> str:
        """ç”Ÿæˆé”€å”®æç¤ºè¯"""
        try:
            # ä½¿ç”¨prompt_generatorç”Ÿæˆä¸ªæ€§åŒ–æç¤ºè¯
            sales_prompt = self.prompt_generator.generate_prompt(sentiment_result, context)

            self.logger.info(f"æˆåŠŸç”Ÿæˆsales_promptï¼Œé•¿åº¦: {len(sales_prompt)}")
            return sales_prompt

        except Exception as e:
            self.logger.error(f"æç¤ºè¯ç”Ÿæˆå¤±è´¥: {e}")

    def _update_state(self, state: dict, processed_text: str, sentiment_result: dict, sales_prompt: str, multimodal_context: dict) -> dict:
        """æ›´æ–°å¯¹è¯çŠ¶æ€ - ç»Ÿä¸€çŠ¶æ€ç®¡ç†æ¨¡å¼"""
        # æå–tokenä¿¡æ¯
        sentiment_tokens = {
            "tokens_used": sentiment_result.get("tokens_used", 0),
            "total_tokens": sentiment_result.get("total_tokens", 0)
        }

        # ä¿®å¤ï¼šç»Ÿä¸€çŠ¶æ€ç®¡ç†ï¼Œç§»é™¤é‡å¤å­˜å‚¨
        # 1. ä¸»è¦æ•°æ®å­˜å‚¨åœ¨æ ¹çº§åˆ«ï¼ˆLangGraphèŠ‚ç‚¹é—´ä¼ é€’ï¼‰
        state["processed_text"] = processed_text
        state["sales_prompt"] = sales_prompt
        state["sentiment_analysis"] = {
            **sentiment_result,
            "processed_input": processed_text,
            "multimodal_context": multimodal_context,
            "agent_id": self.agent_id,
            **sentiment_tokens
        }

        # 2. å¤‡ä»½å­˜å‚¨åœ¨valuesç»“æ„ä¸­ï¼ˆç”¨äºç»Ÿè®¡å’Œè°ƒè¯•ï¼‰
        if state.get("values") is None:
            state["values"] = {}
        if state["values"].get("agent_responses") is None:
            state["values"]["agent_responses"] = {}

        agent_data = {
            "sentiment_analysis": sentiment_result,
            "sales_prompt": sales_prompt,
            "processed_input": processed_text,
            "timestamp": get_current_datetime(),
            **sentiment_tokens
        }

        state["values"]["agent_responses"][self.agent_id] = agent_data

        # æ›´æ–°æ´»è·ƒæ™ºèƒ½ä½“åˆ—è¡¨
        state.setdefault("active_agents", []).append(self.agent_id)

        self.logger.info(f"çŠ¶æ€ä¼ é€’å®Œæˆ - æ ¹çº§åˆ«å­—æ®µ: processed_text({len(processed_text)}), sales_prompt({len(sales_prompt)}), sentiment_analysis")

        return state
