"""
ç¤¾äº¤åª’ä½“å…¬åŸŸå¯¼æµæœåŠ¡

å°è£… LLM è°ƒç”¨ã€æç¤ºè¯æ‹¼è£…å’Œç»“æœè§£æé€»è¾‘ï¼Œä¸ºæ§åˆ¶å™¨æä¾›å¤ç”¨èƒ½åŠ›ã€‚
"""

from __future__ import annotations

import json
from typing import Any

from infra.runtimes import LLMClient, LLMRequest
from libs.types import Message
from schemas.social_media_schema import (
    CommentGenerationRequest,
    ReplyGenerationRequest,
    KeywordSummaryRequest,
)
from utils import get_component_logger


logger = get_component_logger(__name__, "SocialMediaPublicTrafficService")


class SocialMediaServiceError(Exception):
    """ç¤¾äº¤åª’ä½“å¯¼æµæœåŠ¡å¼‚å¸¸"""


class SocialMediaPublicTrafficService:
    """ç¤¾äº¤åª’ä½“å¼•æµæ–‡æ¡ˆç”ŸæˆæœåŠ¡"""

    # ------------------------------ é…ç½®å¸¸é‡ ------------------------------ #
    DEFAULT_PROVIDER = "openrouter"  # ä½¿ç”¨ OpenRouter
    DEFAULT_MODEL = "google/gemini-2.5-flash-preview-09-2025" #å¿«é€Ÿ
    DEFAULT_TEMPERATURE = 0.5  # æ¸©åº¦è®¾ç½®ä¸º 0.5,è€ƒè™‘é£æ§
    DEFAULT_MAX_TOKENS = 400  # è¯„è®ºå’Œå›å¤ç”Ÿæˆçš„æœ€å¤§ token æ•°ï¼ˆé™ä½ä»¥æå‡é€Ÿåº¦ï¼‰
    SUMMARY_MAX_TOKENS = 300  # å…³é”®è¯æ‘˜è¦çš„æœ€å¤§ token æ•°(æ›´ç®€æ´)

    # ------------------------------ å†…éƒ¨å·¥å…·æ–¹æ³• ------------------------------ #

    @classmethod
    async def _invoke_llm(
        cls,
        *,
        system_prompt: str,
        user_prompt: str,
        max_tokens: int,
    ) -> str:
        """è°ƒç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯"""
        client = LLMClient()
        request = LLMRequest(
            id=None,
            provider=cls.DEFAULT_PROVIDER,
            model=cls.DEFAULT_MODEL,
            messages=[
                Message(role="system", content=system_prompt),
                Message(role="user", content=user_prompt),
            ],
            temperature=cls.DEFAULT_TEMPERATURE,
            max_tokens=max_tokens,
        )
        response = await client.completions(request)
        return response.content

    @staticmethod
    def _parse_structured_payload(raw_text: str) -> dict[str, Any]:
        """è§£æLLMè¿”å›å†…å®¹ä¸ºJSONå­—å…¸"""
        text = raw_text.strip()
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            start = text.find("{")
            end = text.rfind("}")
            if start != -1 and end != -1 and start < end:
                snippet = text[start : end + 1]
                try:
                    return json.loads(snippet)
                except json.JSONDecodeError:
                    logger.warning("è§£æLLMç»“æœå¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬")
        return {"message": raw_text}

    @staticmethod
    def _normalize_keywords(value: Any) -> list[str]:
        """æ•´ç†å…³é”®è¯è¾“å‡º"""
        if isinstance(value, list):
            return [str(item).strip() for item in value if str(item).strip()]
        if isinstance(value, str):
            return [item.strip() for item in value.split(",") if item.strip()]
        return []

    @staticmethod
    def _normalize_count(value: Any, fallback: int) -> int:
        """æ•´ç†æ•°é‡å­—æ®µ"""
        if isinstance(value, int):
            return value
        if isinstance(value, str) and value.isdigit():
            return int(value)
        return fallback

    @classmethod
    def _build_comment_prompt(
        cls, request: CommentGenerationRequest
    ) -> tuple[str, str]:
        """å¸–å­è¯„è®ºæç¤ºè¯"""
        system_prompt = """ç¤¾äº¤åª’ä½“è¿è¥ä¸“å®¶ï¼Œä¸¥æ ¼åˆ¤æ–­ç›¸å…³æ€§ã€‚

ä»»åŠ¡æµç¨‹ï¼š
1. ç›¸å…³æ€§åˆ¤æ–­ï¼ˆä¸¥æ ¼ï¼ï¼‰ï¼šäº§å“ä¸å¸–å­å†…å®¹æ˜¯å¦æœ‰ä¸šåŠ¡ç›¸å…³æ€§ï¼Ÿ
   - ç›®æ ‡å—ä¼—æ˜¯å¦é‡å ï¼Ÿäº§å“èƒ½å¦ä¸ºå¸–å­ç”¨æˆ·æä¾›ä»·å€¼ï¼Ÿ
   - äº’åŠ¨æ•°æ®ä»…ä½œæ¬¡è¦å‚è€ƒï¼Œç›¸å…³æ€§æ˜¯å†³å®šæ€§å› ç´ 
   - ä¸ç›¸å…³ç¤ºä¾‹ï¼šå…¬åŸŸè·å®¢å¹³å° vs å–é’èœ = ä¸ç›¸å…³
2. æœ‰ç›¸å…³æ€§â†’ç»§ç»­ï¼›æ— ç›¸å…³æ€§â†’ä»…è¿”å›{"actions":[]}ï¼Œä¸è¦ä»»ä½•å…¶ä»–å­—æ®µ

è¯„è®ºç±»å‹å¤„ç†ï¼ˆä»…åœ¨æœ‰ç›¸å…³æ€§æ—¶ï¼‰ï¼š
- type=0: AIç”Ÿæˆï¼Œæ ¹æ®é£æ ¼å€¾å‘åˆ›ä½œ
- type=1: å›ºå®šæ–‡æ¡ˆï¼Œmessageå­—æ®µå¿…é¡»å®Œå…¨ç­‰äºæä¾›çš„å›ºå®šå†…å®¹

äº’åŠ¨åŠ¨ä½œå»ºè®®ï¼ˆæœ‰ç›¸å…³æ€§æ—¶ï¼‰ï¼š
- å¿…é¡»åŒ…å«å¤šä¸ªåŠ¨ä½œç»„åˆï¼Œä¸è¦åªæœ‰å•ä¸€åŠ¨ä½œ
- æ¨èç»„åˆï¼š[1,2,3] æˆ– [1,3,5] æˆ– [2,3,5,6] ç­‰
- å•ç‹¬çš„[3]æ˜¯ä¸å¤Ÿçš„ï¼Œéœ€è¦ç»„åˆä½¿ç”¨

è¾“å‡ºJSONï¼š
æœ‰ç›¸å…³: {"message":"æ–‡æ¡ˆ","rationale":"åŸå› ","actions":[1,2,3]}
æ— ç›¸å…³: {"actions":[]}

åŠ¨ä½œ: 1=å…³æ³¨ 2=ç‚¹èµ 3=è¯„è®º 4=åˆ†äº« 5=æ”¶è— 6=ä¸»é¡µ"""

        tasks_block = "\n".join(
            [
                f"{idx}. {task.product_content} (ğŸ‘{task.likes_num} ğŸ’¬{task.replies_num} â­{task.favorite_num} ğŸ”„{task.forward_num})"
                for idx, task in enumerate(request.task_list, start=1)
            ]
        )

        user_parts = [
            f"å¹³å°: {request.platform}",
            f"äº§å“: {request.product_prompt}",
            f"ç±»å‹: {request.comment_type}",
        ]
        if request.comment_prompt:
            if request.comment_type == 0:
                user_parts.append(f"é£æ ¼: {request.comment_prompt}")
            else:
                user_parts.append(f"å›ºå®šæ–‡æ¡ˆ(åŸæ ·è¾“å‡º): {request.comment_prompt}")

        user_parts.append(f"\nå¸–å­:\n{tasks_block}")

        return system_prompt, "\n".join(user_parts)

    @classmethod
    def _build_reply_prompt(
        cls, request: ReplyGenerationRequest
    ) -> tuple[str, str]:
        """è¯„è®ºåŒºè¯„è®ºæç¤ºè¯"""
        system_prompt = """ç¤¾äº¤åª’ä½“å®¢æœè¿è¥ä¸“å®¶ï¼Œä¸¥æ ¼åˆ¤æ–­ç›¸å…³æ€§å¹¶å›å¤ç”¨æˆ·è¯„è®ºã€‚

ä»»åŠ¡æµç¨‹ï¼š
1. é€æ¡åˆ¤æ–­æ¯ä¸ªå›å¤å†…å®¹ä¸äº§å“/æœåŠ¡çš„ç›¸å…³æ€§ï¼ˆä¸¥æ ¼ï¼ï¼‰
   - ç”¨æˆ·é—®é¢˜æ˜¯å¦ä¸äº§å“/æœåŠ¡ç›¸å…³ï¼Ÿèƒ½å¦æä¾›æœ‰ä»·å€¼çš„å›å¤ï¼Ÿ
   - ç›¸å…³æ€§æ˜¯å†³å®šæ€§å› ç´ 
2. æœ‰ç›¸å…³æ€§â†’ç”Ÿæˆå›å¤ï¼›æ— ç›¸å…³æ€§â†’è¿”å›ç©ºactions

å›å¤ç±»å‹å¤„ç†ï¼ˆä»…åœ¨æœ‰ç›¸å…³æ€§æ—¶ï¼‰ï¼š
- type=0: AIç”Ÿæˆï¼Œæ ¹æ®é£æ ¼å€¾å‘åˆ›ä½œä¸“ä¸šå›å¤
- type=1: å›ºå®šæ–‡æ¡ˆï¼Œmessageå­—æ®µå¿…é¡»å®Œå…¨ç­‰äºæä¾›çš„å›ºå®šå†…å®¹

äº’åŠ¨åŠ¨ä½œå»ºè®®ï¼ˆæœ‰ç›¸å…³æ€§æ—¶ï¼‰ï¼š
- å¿…é¡»åŒ…å«å¤šä¸ªåŠ¨ä½œç»„åˆ
- æ¨èç»„åˆï¼š[1,2,3] æˆ– [2,3,5] ç­‰
- ä¸è¦åªæœ‰å•ä¸€åŠ¨ä½œ

è¾“å‡ºJSONæ ¼å¼ï¼š
{
  "tasks": [
    {"id":"1","actions":[1,2,3],"message":"å›å¤å†…å®¹"},
    {"id":"2","actions":[],"message":null}
  ]
}

åŠ¨ä½œ: 1=å…³æ³¨ 2=ç‚¹èµ 3=è¯„è®º 4=åˆ†äº« 5=æ”¶è— 6=ä¸»é¡µ"""

        tasks_block = "\n".join(
            [
                f"{idx}. ID={task.id} å†…å®¹: {task.reply_content}"
                for idx, task in enumerate(request.task_list, start=1)
            ]
        )

        user_parts = [
            f"å¹³å°: {request.platform}",
            f"äº§å“: {request.product_prompt}",
            f"ç±»å‹: {request.comment_type}",
        ]
        if request.comment_prompt:
            if request.comment_type == 0:
                user_parts.append(f"é£æ ¼: {request.comment_prompt}")
            else:
                user_parts.append(f"å›ºå®šæ–‡æ¡ˆ(åŸæ ·è¾“å‡º): {request.comment_prompt}")

        user_parts.append(f"\nå¾…å›å¤:\n{tasks_block}")

        return system_prompt, "\n".join(user_parts)

    @classmethod
    def _build_summary_prompt(
        cls, request: KeywordSummaryRequest
    ) -> tuple[str, str]:
        """å…³é”®è¯ç”Ÿæˆæç¤ºè¯"""
        system_prompt = """ä½ æ˜¯ä¸€åç¤¾äº¤åª’ä½“å…³é”®è¯ç”Ÿæˆä¸“å®¶ï¼Œæ ¹æ®äº§å“/æœåŠ¡ç”Ÿæˆé€‚åˆçš„è¥é”€å…³é”®è¯ã€‚

ä»»åŠ¡è¦æ±‚ï¼š
1. æ ¹æ®äº§å“æè¿°ç”Ÿæˆé€‚åˆè¯¥å¹³å°çš„è¥é”€å…³é”®è¯
2. ä¸¥æ ¼éµå®ˆå»é‡è§„åˆ™ï¼šç”Ÿæˆçš„å…³é”®è¯ä¸èƒ½ä¸"å·²æœ‰å…³é”®è¯"é‡å¤
3. ä¸¥æ ¼éµå®ˆæ•°é‡æ§åˆ¶ï¼š
   - expecting_countæ˜¯æœŸæœ›çš„æ€»å…³é”®è¯æ•°ï¼ˆåŒ…å«å·²æœ‰çš„ï¼‰
   - å®é™…ç”Ÿæˆæ•°é‡ = expecting_count - å·²æœ‰å…³é”®è¯æ•°é‡
   - ä¾‹å¦‚ï¼šexpecting_count=6ï¼Œå·²æœ‰4ä¸ªï¼Œåˆ™åªç”Ÿæˆ2ä¸ªæ–°å…³é”®è¯
4. å…³é”®è¯åº”è¯¥ç®€æ´ã€æœ‰é’ˆå¯¹æ€§ã€é€‚åˆç›®æ ‡å¹³å°ç‰¹ç‚¹

è¾“å‡ºJSONæ ¼å¼ï¼š
{
  "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
  "count": 2,
  "summary": "å…³é”®è¯ç”Ÿæˆè¯´æ˜"
}"""

        existing_keywords = request.existing_keywords or []
        existing_count = len(existing_keywords)
        need_generate = max(0, request.expecting_count - existing_count)

        existing_str = ", ".join(existing_keywords) if existing_keywords else "æš‚æ— "

        user_parts = [
            f"å¹³å°: {request.platform}",
            f"äº§å“æˆ–æœåŠ¡: {request.product_prompt}",
            f"æœŸæœ›å…³é”®è¯æ€»æ•°: {request.expecting_count}",
            f"å·²æœ‰å…³é”®è¯({existing_count}ä¸ª): {existing_str}",
            f"éœ€è¦ç”Ÿæˆ: {need_generate}ä¸ªæ–°å…³é”®è¯",
            "",
            "è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚ç”ŸæˆJSONï¼Œkeywordsæ•°ç»„ä¸­åªåŒ…å«æ–°ç”Ÿæˆçš„å…³é”®è¯ï¼Œä¸è¦åŒ…å«å·²æœ‰å…³é”®è¯ã€‚"
        ]

        return system_prompt, "\n".join(user_parts)


__all__ = ["SocialMediaPublicTrafficService", "SocialMediaServiceError"]
