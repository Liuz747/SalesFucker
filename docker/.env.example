# MAS v0.2 Environment Configuration
# Copy this file to .env and fill in your actual values

# === Application Configuration ===
APP_HOST=0.0.0.0
APP_PORT=8000
APP_ENV=development

# === Service Authentication ===
APP_KEY=your_backend_app_key_here
APP_JWT_ISSUER=mas-ai-service
APP_JWT_AUDIENCE=ai-admin
APP_TOKEN_TTL=3600

# === Database Configuration ===
DB_HOST=your-database-instance.region.provider.com
DB_PORT=5432
DB_NAME=mas

# === PostgreSQL Configuration ===
POSTGRES_USER=postgres
POSTGRES_PWD=your-secure-password-here

# === Redis Configuration ===
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_USERNAME=
REDIS_PASSWORD=myredissecret
REDIS_MAX_CONNECTIONS=10
REDIS_TTL=7200

# === Elasticsearch Configuration ===
ELASTIC_HOST=localhost
ELASTIC_PORT=9200
ELASTIC_USER=elastic
ELASTIC_PASSWORD=changeme

# === Milvus Configuration ===
MILVUS_HOST=milvus-standalone
MILVUS_PORT=19530

# === Temporal Configuration ===
TEMPORAL_HOST=localhost
TEMPORAL_PORT=7233
TEMPORAL_NAMESPACE=default
TEMPORAL_RPC_TIMEOUT=30

# === ClickHouse Configuration ===
CLICKHOUSE_PORT=8123
CLICKHOUSE_DB=mas
CLICKHOUSE_USER=clickhouse
CLICKHOUSE_PASSWORD=clickhouse

# === MinIO Configuration ===
MINIO_API_PORT=9050
MINIO_CONSOLE_PORT=9051
MINIO_ROOT_USER=minio
MINIO_ROOT_PWD=miniosecret

# === Langfuse Configuration (use container names when deploying with Docker) ===
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key-here
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key-here
LANGFUSE_HOST=http://langfuse-web:3000

# === LLM Provider API Keys ===
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# === Multi-LLM Configuration ===
DEFAULT_LLM_PROVIDER=openai
FALLBACK_LLM_PROVIDER=anthropic
ENABLE_COST_TRACKING=true
ENABLE_INTELLIGENT_ROUTING=true

# === Debug ===
DEBUG=true
SQLALCHEMY_ECHO=false

# === Logging ===
LOG_LEVEL=INFO
LOG_FILE=logs/mas.log

# === Performance ===
CACHE_TTL=3600

# === Deployment ===
REGISTRY_URL=registry.gitlab.com
CALLBACK_URL=http://your-callback-url.com

# === Nginx Configuration ===
# Server name (use _ for catch-all, or your domain name)
NGINX_SERVER_NAME=_

# HTTP/HTTPS ports
NGINX_PORT=80
NGINX_SSL_PORT=443

# HTTPS/SSL Configuration
# Set to true to enable HTTPS (requires SSL certificates in docker/nginx/ssl/)
NGINX_HTTPS_ENABLED=false
NGINX_SSL_CERT_FILENAME=mas.crt
NGINX_SSL_CERT_KEY_FILENAME=mas.key

# Performance Settings
NGINX_KEEPALIVE_TIMEOUT=65
NGINX_CLIENT_MAX_BODY_SIZE=100M

# Proxy Timeouts (important for AI/ML workloads)
# Set to high values for long-running LLM requests
NGINX_PROXY_READ_TIMEOUT=3600s
NGINX_PROXY_SEND_TIMEOUT=3600s
